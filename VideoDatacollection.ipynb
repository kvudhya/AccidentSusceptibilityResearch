{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBwk2ONJHOoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b0478e-18b3-4d6a-f2b8-05182be3cb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting m3u8\n",
            "  Downloading m3u8-3.4.0-py3-none-any.whl (24 kB)\n",
            "Collecting iso8601\n",
            "  Downloading iso8601-1.1.0-py3-none-any.whl (9.9 kB)\n",
            "Installing collected packages: iso8601, m3u8\n",
            "Successfully installed iso8601-1.1.0 m3u8-3.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting snscrape\n",
            "  Downloading snscrape-0.5.0.20230113-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from snscrape) (2022.7.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from snscrape) (2.25.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from snscrape) (3.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.5.0.20230113\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting schedule\n",
            "  Downloading schedule-1.1.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.1.0\n",
            "['Exit 144', 'Exit 109', 'Exit 142', 'Exit 145 ', 'Exit 10']\n",
            "['MM 145.8 North of Exit 144', 'MM 110.4 Exit 109', 'MM 142.8 Exit 142', 'MM 147.0 Exit 145 Sussex Ave Overpass', 'MM 010.0 North of Exit 10']\n",
            "MM 145.8 North of Exit 144\n",
            "MM 110.4 Exit 109\n",
            "MM 142.8 Exit 142\n",
            "MM 147.0 Exit 145 Sussex Ave Overpass\n",
            "MM 010.0 North of Exit 10\n"
          ]
        }
      ],
      "source": [
        "!pip install m3u8\n",
        "!pip install snscrape\n",
        "!pip install schedule\n",
        "import subprocess\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from pandas import *\n",
        "import re\n",
        "import os\n",
        "import schedule\n",
        "import time\n",
        "import m3u8\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "\n",
        "\n",
        "cameranum = 2\n",
        "url = 'https://www.njta.com/travel-resources/camera-list'\n",
        "page = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "results = soup.find(id=\"list-2\")\n",
        "\n",
        "exit_lists = results.find_all(\"div\", class_ =\"t-cell\" )\n",
        "\n",
        "cameras_List = []\n",
        "\n",
        "for exit in exit_lists:\n",
        "  video_list= exit.find(\"a\", class_=\"stream_video\")\n",
        "  cameras_List.append(video_list.text.strip())\n",
        "\n",
        "m3u8_File_list = []\n",
        "soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "results = soup.find(id=\"list-2\")\n",
        "\n",
        "exit_lists = results.find_all(\"div\", class_ =\"t-cell\" )\n",
        "\n",
        "for exit in exit_lists:\n",
        "  for link in exit.find_all('a',\n",
        "                            attrs={'data-uri' : re.compile(\"^https://\")}):\n",
        "\n",
        "     # display the actual urls\n",
        "\n",
        "    m3u8_File_list.append(link.get('data-uri'))\n",
        "\n",
        "\n",
        "\n",
        "read_file1 = pd.read_excel(\"Final GSP Accident location Data and list (1).xlsx\")\n",
        "csv_file = read_file1.to_csv(\"Final GSP Accident location Data and list.csv\", index = None, header = True)\n",
        "\n",
        "reads = read_csv(\"Final GSP Accident location Data and list.csv\")\n",
        "\n",
        "list_of_locations = reads[\"Accident Locations\"].tolist()\n",
        "\n",
        "sample_locations = list_of_locations[-11:]\n",
        "\n",
        "new_locations =[]\n",
        "for i in range(5):\n",
        "  new_locations.append(sample_locations[i])\n",
        "\n",
        "\n",
        "print(new_locations)\n",
        "\n",
        "new_m3u8_File_list = []\n",
        "\n",
        "for location in new_locations:\n",
        "  for camera in cameras_List:\n",
        "    if location in camera:\n",
        "      new_m3u8_File_list.append(camera)\n",
        "\n",
        "#print(new_m3u8_File_list)\n",
        "non_dup = []\n",
        "\n",
        "\n",
        "\n",
        "for location in new_locations:\n",
        "  for element in new_m3u8_File_list:\n",
        "    if location in element:\n",
        "      locations = [element]\n",
        "\n",
        "  non_dup.append(locations)\n",
        "\n",
        "real_camera_locations = []# import list\n",
        "for real in non_dup:\n",
        "  for real2 in real:\n",
        "    real_camera_locations.append(real2)\n",
        "real_camera_locations[4]= \"MM 010.0 North of Exit 10\"\n",
        "real_camera_locations[2] = 'MM 142.8 Exit 142'\n",
        "print(real_camera_locations)\n",
        "\n",
        "\n",
        "\n",
        "new_m3u8_list = []#new m3u8 file list###\n",
        "for camera in real_camera_locations:\n",
        "  for cameras in cameras_List:\n",
        "    if camera == cameras:\n",
        "      print(cameras)\n",
        "      new_m3u8_list.append(m3u8_File_list[cameras_List.index(cameras)])\n",
        "\n",
        "\n",
        "\n",
        "req = requests.get(new_m3u8_list[cameranum])\n",
        "\n",
        "ts_data = req.text\n",
        "\n",
        "m3u8_ts = m3u8.loads(ts_data)\n",
        "\n",
        "with open(str(real_camera_locations[cameranum])+'.ts','wb') as f:\n",
        "  type(f)\n",
        "  for segment in m3u8_ts.data['segments']:\n",
        "    ts_url= segment['uri']\n",
        "    ts_complete_video = requests.get( 'https://wink.njta.com/201/public/hls/' + (ts_url))\n",
        "    f.write(ts_complete_video.content)\n",
        "\n",
        "def test():\n",
        "    with open(str(real_camera_locations[cameranum])+'1.ts', 'ab') as t:\n",
        "      def data_places():\n",
        "\n",
        "        req = requests.get(new_m3u8_list[cameranum])\n",
        "\n",
        "        ts_data = req.text\n",
        "\n",
        "\n",
        "        m3u8_ts = m3u8.loads(ts_data)\n",
        "\n",
        "        with open(str(real_camera_locations[cameranum])+'.ts','wb') as f:\n",
        "          type(f)\n",
        "          for segment in m3u8_ts.data['segments']:\n",
        "            ts_url= segment['uri']\n",
        "            ts_complete_video = requests.get( 'https://wink.njta.com/201/public/hls/' + (ts_url))\n",
        "            f.write(ts_complete_video.content)\n",
        "          return f\n",
        "      with open(str(real_camera_locations[cameranum])+'.ts', 'rb') as s:\n",
        "        content = s.read()\n",
        "\n",
        "      t.write(content)\n",
        "\n",
        "    schedule.every(1).seconds.do(data_places)\n",
        "    counter = 1\n",
        "    while counter <= 2:\n",
        "      #result = subprocess.run([\"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
        "                                #\"format=duration\", \"-of\",\n",
        "                                # \"default=noprint_wrappers=1:nokey=1\", 'video1.ts'],\n",
        "      #stdout=subprocess.PIPE,\n",
        "      #stderr=subprocess.STDOUT)\n",
        "      #time_duration = float(result.stdout)\n",
        "      schedule.run_pending()\n",
        "      time.sleep(1)\n",
        "      counter = counter + 1\n",
        "\n",
        "for i in range(60):\n",
        "  test()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(['ffmpeg','-i', str(real_camera_locations[cameranum])+'1.ts', str(real_camera_locations[cameranum])+'1.mp4'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wItySAOHx4Sj",
        "outputId": "ab86dfa8-3e76-4a3d-d657-1b0e81fc4af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['ffmpeg', '-i', 'MM 142.8 Exit 1421.ts', 'MM 142.8 Exit 1421.mp4'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}